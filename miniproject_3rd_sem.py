# -*- coding: utf-8 -*-
"""miniproject_3rd_sem.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14AZm-kJ5L4LgSzeN3NoTDbB1uED2rIq7
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/MINI-PROJECT

from google.colab import drive
drive.mount('/content/drive')

!git clone https://github.com/MuhammadMoinFaisal/YOLOv8-DeepSORT-Object-Tracking.git

from IPython.display import Image

# Commented out IPython magic to ensure Python compatibility.
# %cd YOLOv8-DeepSORT-Object-Tracking

!pip install -e '.[dev]'

# Commented out IPython magic to ensure Python compatibility.
# %pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd ./ultralytics/yolo/v8/detect

!pip install roboflow

!pwd

from roboflow import Roboflow
rf = Roboflow(api_key="pR6PTHLdpGFn6wU19jll")
project = rf.workspace("project-pqqvl").project("ppp-jec7g")
dataset = project.version(1).download("yolov5")

!gdown "https://drive.google.com/uc?id=11ZSZcG-bcbueXZC3rN08CM0qqX3eiHxf&confirm=t"

# Commented out IPython magic to ensure Python compatibility.
# %pwd

!unzip deep_sort_pytorch.zip

HOME = '/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/ultralytics/yolo/v8/detect'

# Commented out IPython magic to ensure Python compatibility.

# %cd {HOME}

# Commented out IPython magic to ensure Python compatibility.
# %pwd

# Commented out IPython magic to ensure Python compatibility.
# %env HYDRA_FULL_ERROR=1

# Commented out IPython magic to ensure Python compatibility.
# %cd {dataset.location}



# Commented out IPython magic to ensure Python compatibility.

# %cd {HOME}

!python train.py model=yolov8l.pt data={dataset.location}/data.yaml epochs=50 imgsz=640

# Commented out IPython magic to ensure Python compatibility.
# %pwd

!ls /content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train

Image(filename = r'/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train/confusion_matrix.png', width = 500,height= 450)

Image(filename = r'/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train/R_curve.png', width = 600)

Image(filename = r'/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train/F1_curve.png', width = 500)

Image(filename = r'/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train/PR_curve.png', width = 500)

FImage(filename = r'/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train/results.png', width = 600)

Image(filename = r'/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train/val_batch2_pred.jpg', width =500,height=300)

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}



{dataset.location}

./content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train2/weights/best.pt

!python val.py model='/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train/weights/best.pt' data={dataset.location}/data.yaml

!python predict.py model='/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train/weights/best.pt' \
source='/content/drive/MyDrive/MINI-PROJECT/How plastic bags were supposed to help the planet - BBC News.mp4'

#For test purpose
# Import libraries
import cv2
import numpy as np
from google.colab.output import eval_js
from base64 import b64decode
from ultralytics import YOLO

# Load YOLOv8 model
model = YOLO('/content/drive/MyDrive/MINI-PROJECT/YOLOv8-DeepSORT-Object-Tracking/runs/detect/train2/weights/best.pt')

# Start webcam
def start_webcam():
    display(Javascript('''
        async function startWebcam() {
            const div = document.createElement('div');
            document.body.appendChild(div);

            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({ 'video': true });

            div.appendChild(video);
            video.srcObject = stream;
            await video.play();

            // Resize the output to fit the video element.
            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

            // Create a canvas element to capture the video frame.
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            div.appendChild(canvas);

            // Continuously capture and send frames to Colab
            setInterval(() => {
                canvas.getContext('2d').drawImage(video, 0, 0);
                const frameDataUrl = canvas.toDataURL('image/jpeg', 1.0);
                google.colab.kernel.invokeFunction('detect_objects', [frameDataUrl], {});
            }, 1000 / 5);  // Adjust the frame rate as needed
        }

        startWebcam();
    '''))

# Function to process each frame captured from the webcam
def detect_objects(frame_data_url):
    # Decode base64 frame data
    frame_data = b64decode(frame_data_url.split(',')[1])

    # Read the frame
    frame = cv2.imdecode(np.frombuffer(frame_data, np.uint8), -1)

    # Perform object detection
    results = model(frame)

    # Process the results
    for r in results.pred[0]:
        x1, y1, x2, y2 = map(int, r[:4])
        cls = int(r[5])
        confidence = round(float(r[4]), 2)
        class_name = model.names[cls]

        # Draw bounding box
        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)

        # Display class name and confidence
        text = f"{class_name} {confidence}"
        cv2.putText(frame, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)

    # Display the frame
    cv2.imshow('Webcam', frame)

# Start the webcam and perform object detection
start_webcam()

